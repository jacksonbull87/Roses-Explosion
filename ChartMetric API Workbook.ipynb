{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from cm_api import get_api_token, get_track_metadata, requests, get_chart_data, get_tiktok_chart_data, get_artist_id\n",
    "import pandas as pd\n",
    "import re\n",
    "from cm_config import token\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresh Token for ChartMetric API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save refresh token to variable\n",
    "\n",
    "REFRESH_TOKEN = token['refresh_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api_token and save it to a variable\n",
    "api_token = get_api_token(REFRESH_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Shazam Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shazam chart data\n",
    "shazam_charts = get_chart_data(api_token, '28795304', 'shazam', '2019-08-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shazam_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse shazam data\n",
    "\n",
    "roses_bucket = []\n",
    "for item in shazam_charts:\n",
    "    item_tuple = (item['id'], item['rank'], item['added_at'], item['code2'], item['city'], item['pre_rank'],\n",
    "                 item['peak_rank'], item['peak_date'], item['release_dates'][0])\n",
    "    roses_bucket.append(item_tuple)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pandas dataframe for shazam chart postions\n",
    "\n",
    "df = pd.DataFrame(roses_bucket, columns=['shazam_id', 'rank', 'added_at', 'code2', 'city', 'pre_rank', \n",
    "                                         'peak_rank', 'peak_date', 'release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip white space in code2 column\n",
    "df['code2'] = df['code2'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates columns to datetime\n",
    "\n",
    "df['added_at'] = pd.to_datetime(df['added_at'], format='%Y/%m/%d')\n",
    "df['peak_date'] = pd.to_datetime(df['peak_date'], format='%Y/%m/%d')\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/roses_shazam_chart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open csv file\n",
    "df = pd.read_csv('datasets/roses_shazam_chart', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file to json\n",
    "df.to_json('datasets/roses_shazam_chart.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as excel file\n",
    "df.to_excel('datasets/roses_shazam_chart.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.read_json('datasets/roses_shazam_chart.json')\n",
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_market =  df_json[df_json['code2'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_market['added_at'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.iloc[538]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['added_at'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get itunes Top Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itunes_top = get_chart_data(api_token, '28795304', 'itunes_top', '2019-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse itunes data\n",
    "\n",
    "roses_Itunes_bucket = []\n",
    "for item in itunes_top:\n",
    "    item_tuple = (item['id'], item['code2s'][0],item['code2'], item['release_dates'][0], item['rank'], item['added_at'], \n",
    "                    item['pre_rank'], item['peak_rank'], item['peak_date'])\n",
    "    roses_Itunes_bucket.append(item_tuple)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean iTunes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert itunes data to dataframe\n",
    "\n",
    "itunes_df = pd.DataFrame(roses_Itunes_bucket, columns=['id', 'code2s', 'code2', 'release date', 'rank', 'added_at', 'pre_rank', 'peak_rank', 'peak_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#convert dates columns to datetime\n",
    "\n",
    "itunes_df['release date'] = pd.to_datetime(itunes_df['release date'], format='%Y/%m/%d')\n",
    "itunes_df['added_at'] = pd.to_datetime(itunes_df['added_at'], format='%Y/%m/%d')\n",
    "itunes_df['peak_date'] = pd.to_datetime(itunes_df['peak_date'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save iTunes Data to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itunes_df.to_csv('datasets/roses_itunes_chart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve TikTok Chart data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = ['2020-08-08', '2020-08-15']\n",
    "\n",
    "for date in date_range:\n",
    "    #for each date grab the top 100 tik tok tracks\n",
    "    tt_chart = get_tiktok_chart_data(api_token, 'tracks', date, 'weekly')\n",
    "    \n",
    "    data_bucket = []\n",
    "    for track in tt_chart:\n",
    "        #for each track on the chart, parse the data into a tuple\n",
    "        track_tuple = (track['name'], track['tiktok_artist_names'][0], track['cm_track'], track['album_label'][0], track['release_dates'][0], track['rank'],\n",
    "                      track['weekly_posts'], track['added_at'], track['velocity'], track['pre_rank'], track['peak_rank'], \n",
    "                      track['peak_date'], track['time_on_chart'], track['rankStats'][0]['rank'], track['rankStats'][0]['weekly_posts'], \n",
    "                      track['rankStats'][0]['timestp'], track['rankStats'][-1]['rank'], track['rankStats'][-1]['weekly_posts'], \n",
    "                      track['rankStats'][-1]['timestp'])\n",
    "        #add each tuple to a giant list where all the desired track's metadata will live\n",
    "        data_bucket.append(track_tuple)\n",
    "    #create a dataframe with correct column names\n",
    "    df = pd.DataFrame(data_bucket, columns=['track_name','artist_name', 'cm_id', 'label', 'release_date', 'rank', \n",
    "                                      'weekly_posts', 'add_date', 'velocity', 'pre_rank', 'peak_rank', 'peak_date', 'time_on_chart', \n",
    "                                      'rank_week_start', 'weekly_posts_start', 'week_start_date', 'rank_week_end', 'weekly_posts_end', 'week_end_date'])\n",
    "    #convert date columns to actual datetimes\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], format='%Y/%m/%d')\n",
    "    df['add_date'] = pd.to_datetime(df['add_date'], format='%Y/%m/%d')\n",
    "    df['peak_date'] = pd.to_datetime(df['peak_date'], format='%Y/%m/%d')\n",
    "    df['week_start_date'] = pd.to_datetime(df['week_start_date'], format='%Y/%m/%d')\n",
    "    df['week_end_date'] = pd.to_datetime(df['week_end_date'], format='%Y/%m/%d')\n",
    "    #save dataframes as csv to a folder\n",
    "    df.to_csv('datasets/tiktokweekly_{}.csv'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "ttwk_200502 = pd.read_csv('datasets/tiktokweekly_2020-05-02.csv', index_col=0)\n",
    "ttwk_200509 = pd.read_csv('datasets/tiktokweekly_2020-05-09.csv', index_col=0)\n",
    "ttwk_200516 = pd.read_csv('datasets/tiktokweekly_2020-05-16.csv', index_col=0)\n",
    "ttwk_200523 = pd.read_csv('datasets/tiktokweekly_2020-05-23.csv', index_col=0)\n",
    "ttwk_200530 = pd.read_csv('datasets/tiktokweekly_2020-05-30.csv', index_col=0)\n",
    "ttwk_200606 = pd.read_csv('datasets/tiktokweekly_2020-06-06.csv', index_col=0)\n",
    "ttwk_200613 = pd.read_csv('datasets/tiktokweekly_2020-06-13.csv', index_col=0)\n",
    "ttwk_200620 = pd.read_csv('datasets/tiktokweekly_2020-06-20.csv', index_col=0)\n",
    "ttwk_200627 = pd.read_csv('datasets/tiktokweekly_2020-06-27.csv', index_col=0)\n",
    "ttwk_200704 = pd.read_csv('datasets/tiktokweekly_2020-07-04.csv', index_col=0)\n",
    "ttwk_200718 = pd.read_csv('datasets/tiktokweekly_2020-07-18.csv', index_col=0)\n",
    "ttwk_200725 = pd.read_csv('datasets/tiktokweekly_2020-07-25.csv', index_col=0)\n",
    "ttwk_200801 = pd.read_csv('datasets/tiktokweekly_2020-08-01.csv', index_col=0)\n",
    "ttwk_200808 = pd.read_csv('datasets/tiktokweekly_2020-08-08.csv', index_col=0)\n",
    "ttwk_200815 = pd.read_csv('datasets/tiktokweekly_2020-08-15.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat([ttwk_200502,ttwk_200509,ttwk_200516,ttwk_200523, ttwk_200530, ttwk_200606, ttwk_200613, ttwk_200620, ttwk_200627,\n",
    "          ttwk_200704, ttwk_200718, ttwk_200725, ttwk_200801, ttwk_200808, ttwk_200815])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save master df to csv file\n",
    "\n",
    "master_df.to_csv('datasets/historic_ttwk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('datasets/historic_ttwk.csv', index_col=0)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many unique songs\n",
    "\n",
    "print(\"Number of Unique Tracks: \", master_df['track_name'].nunique())\n",
    "print(\"Number of Unique Artists: \", master_df['artist_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add CM ID for each artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Up Master Dataframe of Weekly TikTok Chart Data (08-15-20 thru 05-02-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('datasets/historic_ttwk.csv', index_col=0)\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate Artists with Top 10 Ranked Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find a list of artists who have been ranked in the past 4 months\n",
    "\n",
    "top10_rankings = master_df[master_df['rank'] < 11]\n",
    "top10_ttartists = list(top10_rankings['artist_name'].unique())\n",
    "top10_ttartists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DIctionary of Artist Chartmetric IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a dictionary consisting of artists and their associated chartmetric IDs so that we can retreive social media\n",
    "#data for each artist\n",
    "\n",
    "cm_artistIDs = []\n",
    "for artist in top10_ttartists:\n",
    "    cm_id = get_artist_id(api_token, artist, 'artists')\n",
    "    cm_artistIDs.append(cm_id)\n",
    "    \n",
    "cm_artistIDs_dict = {}\n",
    "\n",
    "for key in top10_ttartists:\n",
    "    for value in cm_artistIDs:\n",
    "        cm_artistIDs_dict[key] = value\n",
    "        cm_artistIDs.remove(value)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Dictionary Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle dictionary so I don't have to waste my api calls and I can just open this up whenever I want\n",
    "# cm_artistIDs_dict\n",
    "\n",
    "file_to_write = open(\"cm_artistID_dictionary.pickle\", \"wb\")\n",
    "pickle.dump(cm_artistIDs_dict, file_to_write)\n",
    "\n",
    "file_to_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Pickled Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = open(\"cm_artistID_dictionary.pickle\", \"rb\")\n",
    "cm_artistIDs = pickle.load(file_input)\n",
    "file_input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_artistIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Fan Metrics for Top 10 Ranked Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cm_api import get_fan_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get spotify popularity metrics for each artist and save to a csv file\n",
    "artist_no_data_avail = []\n",
    "success_list = []\n",
    "for artist in cm_artistIDs:\n",
    "    if isinstance(cm_artistIDs[artist], type(None)):\n",
    "        print(artist, ' has no ChartMetric ID')\n",
    "        print('/n')\n",
    "        artist_no_data_avail.append(artist)\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        data = get_fan_metrics(api_token, cm_artistIDs[artist], 'spotify', '2019-09-02', 'popularity')\n",
    "        data_bucket = []\n",
    "        if isinstance(data, type(None)):\n",
    "            continue\n",
    "        success_list.append(artist)\n",
    "        for record in data['popularity']:\n",
    "            if record:\n",
    "                record_tuple = (record['timestp'], artist, cm_artistIDs[artist] , record['value'])\n",
    "                data_bucket.append(record_tuple)\n",
    "            else:\n",
    "                continue\n",
    "        df = pd.DataFrame(data_bucket, columns=['timestamp', 'artist', 'cm_artist_id', 'popularity'])\n",
    "        df.to_csv('datasets/top10artists_popularity_historic_data/{}_spotpop.csv'.format(artist))\n",
    "        \n",
    "\n",
    "\n",
    "print('Out of {} artists who had tracks ranked in the top 10, only {} had IDs'.format(len(cm_artistIDs), len(success_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge artist dat into one DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets/top10artists_popularity_historic_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-626757e05521>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#set working directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/top10artists_popularity_historic_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets/top10artists_popularity_historic_data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "#set working directory\n",
    "os.chdir('datasets/top10artists_popularity_historic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all csv files in the folder\n",
    "#use glob pattern matching -> extension = 'csv'\n",
    "#save result in list -> all_filenames\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "# print(all_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv('top10artists_popmetrics_mstr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artist</th>\n",
       "      <th>cm_artist_id</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-02T00:00:00.000Z</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>206548</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-03T00:00:00.000Z</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>206548</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-04T00:00:00.000Z</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>206548</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-05T00:00:00.000Z</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>206548</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-06T00:00:00.000Z</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>206548</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2020-08-29T00:00:00.000Z</td>\n",
       "      <td>YFN Lucci</td>\n",
       "      <td>5314</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2020-08-30T00:00:00.000Z</td>\n",
       "      <td>YFN Lucci</td>\n",
       "      <td>5314</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2020-08-31T00:00:00.000Z</td>\n",
       "      <td>YFN Lucci</td>\n",
       "      <td>5314</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2020-09-01T00:00:00.000Z</td>\n",
       "      <td>YFN Lucci</td>\n",
       "      <td>5314</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2020-09-02T00:00:00.000Z</td>\n",
       "      <td>YFN Lucci</td>\n",
       "      <td>5314</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6634 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp     artist  cm_artist_id  popularity\n",
       "Unnamed: 0                                                               \n",
       "0           2019-09-02T00:00:00.000Z  BLACKPINK        206548          85\n",
       "1           2019-09-03T00:00:00.000Z  BLACKPINK        206548          84\n",
       "2           2019-09-04T00:00:00.000Z  BLACKPINK        206548          84\n",
       "3           2019-09-05T00:00:00.000Z  BLACKPINK        206548          84\n",
       "4           2019-09-06T00:00:00.000Z  BLACKPINK        206548          84\n",
       "...                              ...        ...           ...         ...\n",
       "350         2020-08-29T00:00:00.000Z  YFN Lucci          5314          71\n",
       "351         2020-08-30T00:00:00.000Z  YFN Lucci          5314          71\n",
       "352         2020-08-31T00:00:00.000Z  YFN Lucci          5314          71\n",
       "353         2020-09-01T00:00:00.000Z  YFN Lucci          5314          71\n",
       "354         2020-09-02T00:00:00.000Z  YFN Lucci          5314          71\n",
       "\n",
       "[6634 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10artists_mstr = pd.read_csv('top10artists_popmetrics_mstr.csv', index_col=0)\n",
    "top10artists_mstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          6634\n",
       "unique           28\n",
       "top       Pop Smoke\n",
       "freq            355\n",
       "Name: artist, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "361.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
